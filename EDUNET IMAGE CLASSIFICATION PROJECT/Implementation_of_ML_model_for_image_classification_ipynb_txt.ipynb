{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPNs3zS4xuB8"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7cdSL-ExuCF"
      },
      "source": [
        "# Edunet Foundation : Class Room Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1roztsAAxuCH"
      },
      "source": [
        "## Lab 31: Classification of Images from the CIFAR-10 Dataset using ANN (MLP) & CNN\n",
        "\n",
        "### Objective:\n",
        "The objective of the \"Classification of Images from the CIFAR-10 Dataset using ANN (MLP) & CNN\" lab is to equip learners with the knowledge and skills to build and evaluate image classification models using Artificial Neural Networks (ANN) and Convolutional Neural Networks (CNN). The course begins with fundamental concepts of neural networks and image data representation. It advances to implementing Multilayer Perceptrons (MLP) and CNNs using Python libraries such as TensorFlow and Keras. Learners will gain hands-on experience in preprocessing image data, designing network architectures, and training models to classify images into ten different categories from the CIFAR-10 dataset. By the end of the lab, learners will be proficient in applying ANN and CNN techniques to image classification tasks, enabling them to tackle similar problems in real-world applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOObV9nguhe4"
      },
      "source": [
        "# Classification of Images from the CIFAR-10 Dataset using  ANN (MLP) & CNN.\n",
        "The CIFAR-10 dataset consists of color 60,000 images each with 32 x 32 pixel in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.\n",
        "\n",
        "Class labels are:\n",
        "\n",
        "airplane : 0, automobile : 1, bird : 2, cat : 3, deer : 4, dog : 5, frog : 6, horse : 7, ship : 8, truck : 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuVRILk-vaBb"
      },
      "source": [
        "### Import Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Elui-qSxuCP"
      },
      "outputs": [],
      "source": [
        "#!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmd1PDuTvVlk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kBBFIXWxuCU"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSkdgKW2xuCW"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU00AMY9vLDb"
      },
      "source": [
        "# Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZjAFqimvIB_"
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "#physical_devices\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXnz2p3AvCIK"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgLDohXGuDVH"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R8U7q3evu8t"
      },
      "source": [
        "## Show some sample images of data set with corresponding labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egv3tZ3WvmpF"
      },
      "outputs": [],
      "source": [
        "cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "print('Example training images and their labels: ' + str([x[0] for x in y_train[0:10]]))\n",
        "print('Corresponding classes for the labels: ' + str([cifar10_classes[x[0]] for x in y_train[0:10]]))\n",
        "\n",
        "fig, axarr = plt.subplots(1, 10)\n",
        "fig.set_size_inches(20, 6)\n",
        "\n",
        "for i in range(10):\n",
        "    image = x_train[i]\n",
        "    axarr[i].imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tFczNU9wZGM"
      },
      "outputs": [],
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ami08m2xXCn"
      },
      "source": [
        "## Preparing the dataset\n",
        "Normalize the input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x82EXLcHwmyP"
      },
      "outputs": [],
      "source": [
        "X_train = x_train / 255.0\n",
        "X_test = x_test / 255.0\n",
        "# Every Neuron is expected to have value from 0 to 1 to converge quickly(Gradient Descent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz-HdQr8yBZg"
      },
      "source": [
        "# MLP Network\n",
        "\n",
        "* I/p Layer - Flatten\n",
        "* Hidden layer - 2048, AF = 'RELU'\n",
        "* O/p Layer - 10 , AF-Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZKiN6kQyAzy"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0MvEfT6xuCi"
      },
      "outputs": [],
      "source": [
        "ann = keras.Sequential()\n",
        "ann.add(Flatten(input_shape=(32,32,3)))\n",
        "ann.add(Dense(2048,activation='relu'))\n",
        "ann.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6QQHuU9xuCi"
      },
      "outputs": [],
      "source": [
        "ann.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPJg0WzYySF5"
      },
      "outputs": [],
      "source": [
        "ann.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtqrelqmyTb3"
      },
      "outputs": [],
      "source": [
        "history = ann.fit(X_train ,y_train,epochs=10,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVqc62RX2f_r"
      },
      "source": [
        "#### With the below simple function we will be able to plot our training history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrCCccRs1Evc"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH5pf7UX1WD9"
      },
      "source": [
        "## CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWU4yBGO1X8A"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8vLr0nn1rM7"
      },
      "outputs": [],
      "source": [
        "cnn = keras.Sequential()\n",
        "cnn.add(Conv2D(32, kernel_size= (3,3), strides=(1,1), padding='same', activation='relu', input_shape = (32,32,3)))\n",
        "cnn.add(MaxPooling2D((2,2)))\n",
        "cnn.add(Conv2D(64, kernel_size= (3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "cnn.add(MaxPooling2D((2,2)))\n",
        "cnn.add(Conv2D(128, kernel_size= (3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "cnn.add(MaxPooling2D((2,2)))\n",
        "cnn.add(Conv2D(256, kernel_size= (3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "cnn.add(MaxPooling2D((2,2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(64,activation='relu'))\n",
        "cnn.add(Dropout(0.3))\n",
        "cnn.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ6FMNZN1-se"
      },
      "outputs": [],
      "source": [
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J8IZOVD2E7-"
      },
      "outputs": [],
      "source": [
        "cnn.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history = cnn.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ndaiS363B5K"
      },
      "outputs": [],
      "source": [
        "def plotLosses(history):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DRllhYS3IwI"
      },
      "outputs": [],
      "source": [
        "plotLosses(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWCQgFgr3fdI"
      },
      "outputs": [],
      "source": [
        "def plotAccuracy(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9tRUozK3zwi"
      },
      "outputs": [],
      "source": [
        "plotAccuracy(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaA411pYxuCr"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "cnn.save('imgmodel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFSRVvFixuCr"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = tf.keras.models.load_model('imgmodel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFczeFMVxuCs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Add a batch dimension to the input\n",
        "x_test_sample = np.expand_dims(x_test[20], axis=0)\n",
        "\n",
        "# Now pass it to the model for prediction\n",
        "model.predict(x_test_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9tLWmfnxuCs"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_test[20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao61wx45xuC2"
      },
      "outputs": [],
      "source": [
        "# Example: if you have class names like this\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  # replace with your actual class names\n",
        "\n",
        "# Get the prediction probabilities\n",
        "predictions = model.predict(x_test_sample)\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "# Get the corresponding class name\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "print(f\"The predicted class is: {predicted_class_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqn8F8MbxuC2"
      },
      "source": [
        "# Happy Learning"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}